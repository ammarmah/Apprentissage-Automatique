# -*- coding: utf-8 -*-
"""FahreinheitToCelsius.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PI9Wjg2wciNyrAgam0kH6dzEDfZnn9UJ
"""

#import dependencies
import tensorflow as tf
tf.logging.set_verbosity(tf.logging.ERROR)
#tell the tensorflow to show error messages only
#why ? I don't know :)
import numpy as np

#set-up TRAINING data
celsius_q = np.array([-40, -10, 0, 8, 15, 22, 38], dtype = float)
fahrenheit_a = np.array([-40, 14, 32, 46, 59, 72, 100], dtype = float)

#CREATE A MODEL

#BUILD a layer
l0 = tf.keras.layers.Dense(units= 1, input_shape=[1])

#assemble the layer(s) into the model
model = tf.keras.Sequential([l0])

#COMPILE the model, with loss and optimizer functions
#loss fn: way of measuring how far from desired outcomes are the predictions
#optimizer fn: way of adjusting internal values in order to reduce the loss
model.compile(loss = "mean_squared_error", optimizer = tf.keras.optimizers.Adam(0.1))

#TRAIN the model
#training a model is an act of calculating current loss of a model and then improving it
history = model.fit(celsius_q, fahrenheit_a, epochs = 500, verbose = False)
print("Finished training the model")

#use the model to PREDICT values
print(model.predict([100.00]))

#looking at the layer weights
#print internal variables of the dense layer
print("these are the layer variables: {}".format(l0.get_weights()))

"""The code presented altogether:

l0 = tf.keras.layers.Dense(units=1, input_shape=[1]) 

model = tf.keras.Sequential([l0])

model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))

history = model.fit(celsius_q, fahrenheit_a, epochs=500, verbose=False)

model.predict([100.0])
"""

''' another model with multiple layers
l0 = tf.keras.layers.Dense(units=4, input_shape=[1])  
l1 = tf.keras.layers.Dense(units=4)  
l2 = tf.keras.layers.Dense(units=1)  
model = tf.keras.Sequential([l0, l1, l2])
model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(0.1))\
print("These are the l2 variables: {}".format(l2.get_weights()))
'''

#display training statistics
import matplotlib.pyplot as plt

plt.xlabel("Epoch Number")
plt.ylabel("Loss Magnitude")
plt.plot(history.history["loss"])